```{r}
#import data
library(tidyverse)

data<-as_tibble(read.csv("~/MSDS/STAT6021/Project2/kc_house_data.csv"))

```

#### Define categorical variables 

Change waterfront to categorical.
```{r}
data$waterfront <- factor(data$waterfront)
levels(data$waterfront) <- c("no","yes") 
```

Change view to categorical. 
```{r}
data$view <- factor(data$view)
levels(data$view) <- c("no", "yes", "yes", "yes", "yes") 
```

#### Create new variables 
Create categorical variable 'renovated' for houses showing a renovation:
```{r}
data <- data %>% mutate(renovated = yr_renovated>0)
data$renovated<-factor(data$renovated)
levels(data$renovated)<- c("no","yes") 
```



Create variable age from (2015-yr_built) to age. 
```{r}
data <- mutate(data, age = 2015 - yr_built)

```

Create variable since_reno. This is the the "age" of the house since its last renovation. For houses without renovations, the value is identical to "age", for those with renovations, the "age" of the house is reset to the time since the renovation:
```{r}
data<-data %>% mutate(since_reno = ifelse(renovated=='no', age, 2015-yr_renovated ))
```

Create categorical variable over_budget for our hypothetical Seattle transplant finding a home for  ($718,000). 
```{r}
data <- data %>% mutate(over_budget = price > 718000)
data$over_budget <- factor(data$over_budget)
levels(data$over_budget) <- c("no","yes") 
```

Change sqft_basement to basement. 
```{r}
data <- data %>% mutate(has_basement = sqft_basement>0)
data$has_basement <- factor(data$has_basement)
levels(data$has_basement) <- c("no","yes") 
```

Change date to season. 
```{r}
data$date <- substr(data$date,start=1,stop=8)
data$year <- substr(data$date,start=1,stop=4)
data$month <- substr(data$date, start=5, stop=6)
data$day <- substr(data$date, start=7, stop=8)
data$season <- ifelse(data$month=="05"|
                       data$month=="06"|
                       data$month=="07"|
                       data$month=="08"|
                       data$month=="09","summer","non-summer")
```


So what are we working with?
```{r}
names(data)
```


House id and zipcode are not going into the model so we'll delete them.
```{r}
data<-data %>% select(-id, -zipcode)
```

Let's have a look at our quatitative variables to find correlations:
```{r}
quant_cor <- data %>% 
  select(price, bedrooms, bathrooms, sqft_living, sqft_above, sqft_lot, floors, 
                       condition, grade, sqft_basement, lat, long, sqft_living15,
                       sqft_lot15, age, since_reno) %>%
  cor(use = 'complete.obs') %>% 
  round(2)

corrplot(quant_cor, type = "lower", order = "FPC", diag = T, method = 'square',
         col = COL2('PuOr'),
         tl.col = "black", tl.srt = 45,
         title = "Correlation matrix of numerical variables", 
         mar=c(0,0,1,0))
```

For better or worse, we see strong negative correlations with a number of variables like square footage, bathrooms, and floors. Somewhat surprisingly there is a positive correlation between age and condition. 

before proceding, we will split our data into a training and test set with an 80/20 split:

```{r}
set.seed(206)
samp<-sample.int(nrow(Data), floor(.80*nrow(Data)), replace = F)
train<-data[samp, ] ##training data frame
test<-data[-samp, ] ##test data frame
```


We will now try some automated search procedures to fit a linear regression model with our features.
We obviously cannot include data which contains the age of the house like yr_built, or since_reno (which is mostly identical to age), and yr_renovated is a bit of a cheat since this gives a terminus ante quem for the age of the house. So our slightly reduced data set is regdata:

```{r}
regdata<-train %>% select(-yr_built, -since_reno, -year, -month, -day, -yr_renovated)
```

```{r}
##intercept only model
regnull <- lm(age~1, data=regdata)
##model with all predictors
regfull <- lm(age~., data=regdata)
```

We will attempt a step-wise search of the models from the intercept-only model through the full training regdata.
```{r}
step(regnull, scope=list(lower=regnull, upper=regfull), direction="both")

```
So our search outputs a big-honking model with 16 predictors. We will inspect the model and see what features seem valuable and which we may want to eliminate.

```{r}
starting_model<-lm(age ~ bathrooms + long + condition + renovated + 
    floors + price + grade + bedrooms + lat + sqft_living + over_budget + 
    view + waterfront + sqft_lot + has_basement + sqft_above, 
    data = regdata)
summary(starting_model)
```
Our p-value suggests our model is useful for predicting the response. Moreover, the model indicates that all of these features are significant in the presence of the rest. sqft_living and sqft_above are shown as slightly less significant. Indeed the pair have a 0.875 correlation.

```{r}
cor(regdata$sqft_above, regdata$sqft_living, method='pearson')
```

Before deciding what features, if any, we want to drop, we will do the usual tests of the assumptions for linear models.

```{r}
library(faraway)
vif(starting_model)
```

As expected, sqft_living and sqft_above have high VIF scores due to their close correlation.

Let's check our residuals:
```{r}
yhat<-starting_model$fitted.values
res<-starting_model$residuals
Data<-data.frame(regdata, yhat, res)
##residual plot
ggplot(Data, aes(x=yhat,y=res))+
geom_point()+
geom_hline(yintercept=0, color="red")+
labs(x="Fitted y", y="Residuals", title="Residual Plot of Starting Model")
```
That is definitely not a nice even spread. The residuals appear biased. The results are showing a linear pattern which could be due to a lurking variable not in the data.

Checking the ACF:
```{r}
acf(res, main="ACF of Residuals from Reduced Model")
```

The ACF plot does show a few points which go beyond the bounds of significance.

Finally a QQ plot. Based on our residual plot, we don't expect a nice normal distribution:

```{r}
qqnorm(res)
qqline(res, col="red")
```

Our sample quantiles veer far off, indicating some right-skew and fat tails.

It's not clear how we should transform our data to better meet the assumptions of linear aggression. We can try eliminating some variables, however, and see if we can get a better model with fewer features.

A reminder our starting model was: formula = age ~ bathrooms + long + condition + renovated + 
    floors + price + grade + bedrooms + lat + sqft_living + over_budget + 
    view + waterfront + sqft_lot + has_basement + sqft_above
    
We will eliminate sqft_above, as it interferes with sqft_living. Also, over_budget is contained in price.

So our reduced model is:
formula = age ~ bathrooms + long + condition + renovated + 
    floors + price + grade + bedrooms + lat + sqft_living +
    view + waterfront + sqft_lot + has_basement 
    
```{r}


reduced<-lm(age ~ bathrooms + long + condition + renovated + 
    floors + price + grade + bedrooms + lat + sqft_living +
    view + waterfront + sqft_lot + has_basement, data=regdata)
summary(reduced)
```

This model is likewise significant by its p-value, though now has_basement is less significant in the presence of the other predictors. We can do a partial F test between the full and reduced models.

```{r}
anova(reduced, starting_model)
```

We get a significant result, indicating that the coefficients for one of the predictors dropped (over_budget and sqft_above) is non-zero and we should go with the full model.

We can try adding over_budget back in as it was highly significant in the full model, and we can drop has_basement since it was less significant in the first reduced model:

```{r}
starting_model_exp<-lm(exp(age) ~ bathrooms + long + condition + renovated + 
    floors + price + grade + bedrooms + lat + sqft_living + over_budget + 
    view + waterfront + sqft_lot + has_basement + sqft_above, 
    data = regdata)
summary(starting_model_exp)
```

```{r}
reduced2<- lm(age ~ bathrooms + long + condition + renovated + 
   over_budget + floors + price + grade + bedrooms + lat + sqft_living +
   view + waterfront + sqft_lot,  data=regdata)
summary(reduced2)
        
```

```{r}
anova(reduced2, starting_model)
```

Even with the collinearity, our anova test indicates that we have non-zero coefficients for our dropped predictors and so we go with the starting model.

Now we can test it against the test set to see how we do.

How often does our model get within 5 years of the correct age?

```{r}
preds<-predict(starting_model, newdata = test, interval = 'confidence')

accuracy<-function(predict_vec, threshold){
  sum(abs(predict_vec[,1]-test$age)<=threshold)/dim(predict_vec)[1]}

accuracy(preds, 5)
```

Not awesome predictive power.

10 years?
```{r}
accuracy(preds,10)
```

Jumps close to 50%


